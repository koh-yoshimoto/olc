name: Release

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      tag:
        description: 'Tag to release'
        required: true
        type: string

permissions:
  contents: write

jobs:
  build:
    name: Build and Release
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.21'

    - name: Get version
      id: version
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "VERSION=${{ github.event.inputs.tag }}" >> $GITHUB_OUTPUT
        else
          echo "VERSION=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
        fi

    - name: Build binaries
      run: |
        export VERSION=${{ steps.version.outputs.VERSION }}
        export COMMIT=${GITHUB_SHA::8}
        export BUILD_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        make build-all

    - name: Create archives
      run: make archive

    - name: Generate checksums
      run: |
        cd dist
        sha256sum * > checksums.txt

    - name: Create Release
      uses: softprops/action-gh-release@v1
      with:
        tag_name: ${{ steps.version.outputs.VERSION }}
        name: OLC ${{ steps.version.outputs.VERSION }}
        draft: false
        prerelease: false
        generate_release_notes: true
        files: |
          dist/*.tar.gz
          dist/*.zip
          dist/checksums.txt
        body: |
          ## OLC (Ollama Client) ${{ steps.version.outputs.VERSION }}
          
          A sleek command-line interface client for interacting with Ollama API in private network environments.
          
          ### Downloads
          
          Choose the appropriate binary for your platform:
          
          | Platform | Architecture | Download |
          |----------|--------------|----------|
          | Linux | x86_64 | olc-linux-amd64.tar.gz |
          | Linux | ARM64 | olc-linux-arm64.tar.gz |
          | macOS | Intel | olc-darwin-amd64.tar.gz |
          | macOS | Apple Silicon | olc-darwin-arm64.tar.gz |
          | Windows | x86_64 | olc-windows-amd64.zip |
          | Windows | ARM64 | olc-windows-arm64.zip |
          
          ### Installation
          
          1. Download the appropriate archive for your platform
          2. Extract the binary
          3. Place it in your PATH
          
          ### Usage
          
          ```bash
          # Configure your Ollama server
          olc config set ip your-ollama-server-ip
          olc config set model your-preferred-model
          
          # Start chatting
          olc chat
          
          # Generate text
          olc generate --prompt "Your prompt here"
          
          # Manage models
          olc model list
          ```
          
          ### Verification
          
          Verify the integrity of your download using the provided checksums:
          ```bash
          sha256sum -c checksums.txt
          ```
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}